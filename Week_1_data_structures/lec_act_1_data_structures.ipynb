{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lec_act_1_data_structures.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture goals\n",
    "\n",
    "1. Understand the benefit of numpy (over lists) for operating over lists of numbers\n",
    "2. Introduction to numpy-style array operations (slicing, mean)\n",
    "3. Dictionaries for data encapsulation\n",
    "4. Debugging strategies: Showing Variables in the variable window, interpretting errors\n",
    "\n",
    "Some \"how tos\" for Jupyter notebooks/autograder if you're starting here.\n",
    "\n",
    "- Put the cursor in a cell and hit shift-return to execute the cell. You can also click on the triangle in the upper left\n",
    "- Each problem has a \"grading\" cell. This is, essentially, the tests the auto-grader will run\n",
    "- If you see triple dots ... or the word \"pass\" this is short-hand for \"put your code here\". Python will ignore these, but you should delete them as you complete problems\n",
    "- You can add as many variables and cells as you want, but don't change the names of the variables given to you. The autograder is expecting those names\n",
    "- When you think everything is working, hit Restart and Run All (buttons at the top). This will make sure the code you turn in is the same code Gradescope runs. We do check for this; look at the code cells - they have a number next to them. If you've done a Restart and Run all those should start from 1\n",
    "- If you click on the colored bar to the left of the cell (or output) this hides the contents of the cell. Try it to hide this cell and bring it back\n",
    "\n",
    "Lecture activity hand-ins for in-person class: Get as much done as you can before Wednesday class, but if you get stuck, just stop and bring your questions to class. There is no penalty for re-submitting after class (just get it in before the late deadline). These \"late\" days do not count toward your late day allotment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: otter-grader in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (5.5.0)\n",
      "Requirement already satisfied: dill in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (0.3.8)\n",
      "Requirement already satisfied: jinja2 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (3.1.3)\n",
      "Requirement already satisfied: nbformat in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (5.10.3)\n",
      "Requirement already satisfied: pandas in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (2.2.1)\n",
      "Requirement already satisfied: PyYAML in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (6.0.1)\n",
      "Requirement already satisfied: python-on-whales in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (0.70.1)\n",
      "Requirement already satisfied: requests in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (2.31.0)\n",
      "Requirement already satisfied: wrapt in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (1.16.0)\n",
      "Requirement already satisfied: jupytext in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (1.16.1)\n",
      "Requirement already satisfied: click in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (8.1.7)\n",
      "Requirement already satisfied: fica>=0.3.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (0.3.1)\n",
      "Requirement already satisfied: ipython in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (8.22.2)\n",
      "Requirement already satisfied: astunparse in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (1.6.3)\n",
      "Requirement already satisfied: ipywidgets in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (8.1.2)\n",
      "Requirement already satisfied: ipylab in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (1.0.0)\n",
      "Requirement already satisfied: nbconvert in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from otter-grader) (7.16.3)\n",
      "Requirement already satisfied: docutils in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from fica>=0.3.1->otter-grader) (0.20.1)\n",
      "Requirement already satisfied: sphinx in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from fica>=0.3.1->otter-grader) (7.2.6)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from astunparse->otter-grader) (0.43.0)\n",
      "Requirement already satisfied: six<2.0,>=1.6.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from astunparse->otter-grader) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipywidgets->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipywidgets->otter-grader) (5.14.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipywidgets->otter-grader) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipywidgets->otter-grader) (3.0.10)\n",
      "Requirement already satisfied: decorator in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from ipython->otter-grader) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jinja2->otter-grader) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=1.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupytext->otter-grader) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupytext->otter-grader) (0.4.0)\n",
      "Requirement already satisfied: packaging in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupytext->otter-grader) (24.0)\n",
      "Requirement already satisfied: toml in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupytext->otter-grader) (0.10.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (5.7.2)\n",
      "Requirement already satisfied: jupyterlab-pygments in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbconvert->otter-grader) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbformat->otter-grader) (2.19.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbformat->otter-grader) (4.21.1)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pandas->otter-grader) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pandas->otter-grader) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pandas->otter-grader) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pandas->otter-grader) (2024.1)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=1.9 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from python-on-whales->otter-grader) (2.6.4)\n",
      "Requirement already satisfied: tqdm in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from python-on-whales->otter-grader) (4.66.2)\n",
      "Requirement already satisfied: typer>=0.4.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from python-on-whales->otter-grader) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from python-on-whales->otter-grader) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from requests->otter-grader) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from requests->otter-grader) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from requests->otter-grader) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from requests->otter-grader) (2024.2.2)\n",
      "Requirement already satisfied: webencodings in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert->otter-grader) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jedi>=0.16->ipython->otter-grader) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat->otter-grader) (0.18.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupyter-core>=4.7->nbconvert->otter-grader) (4.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from markdown-it-py>=1.0->jupytext->otter-grader) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from nbclient>=0.5.0->nbconvert->otter-grader) (8.6.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pexpect>4.3->ipython->otter-grader) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->otter-grader) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pydantic!=2.0.*,<3,>=1.9->python-on-whales->otter-grader) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from pydantic!=2.0.*,<3,>=1.9->python-on-whales->otter-grader) (2.16.3)\n",
      "Requirement already satisfied: typer-slim==0.12.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from typer-slim[standard]==0.12.0->typer>=0.4.1->python-on-whales->otter-grader) (0.12.0)\n",
      "Requirement already satisfied: typer-cli==0.12.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from typer>=0.4.1->python-on-whales->otter-grader) (0.12.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from typer-slim[standard]==0.12.0->typer>=0.4.1->python-on-whales->otter-grader) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from typer-slim[standard]==0.12.0->typer>=0.4.1->python-on-whales->otter-grader) (13.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from beautifulsoup4->nbconvert->otter-grader) (2.5)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (1.0.8)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (1.0.6)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (2.0.5)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (1.1.10)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (1.0.7)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (2.2.0)\n",
      "Requirement already satisfied: babel>=2.9 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (2.14.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (0.7.16)\n",
      "Requirement already satisfied: imagesize>=1.3 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from sphinx->fica>=0.3.1->otter-grader) (1.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from stack-data->ipython->otter-grader) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from stack-data->ipython->otter-grader) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from stack-data->ipython->otter-grader) (0.2.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->otter-grader) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages (from jupyter-client>=6.1.12->nbclient>=0.5.0->nbconvert->otter-grader) (6.4)\n"
     ]
    }
   ],
   "source": [
    "# Safety check - if you did not install numpy or otter-grader correctly this should do it for you\n",
    "#  If you have installed everything already, it should spit out a bunch of \"requirement already satisfied\" messages\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install otter-grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access all numpy functions as np.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Question 1: Stats on a list\n",
    "\n",
    "## calculate stats on a list\n",
    "\n",
    "TODO: Given a list of numbers (as a list) \n",
    "- Calculate the mean of the negative and positive values\n",
    "- Count the total number of negative/positive values\n",
    "- Store the values in a dictionary\n",
    "\n",
    "This is (mostly) just practice with a **for** loop and an **if** statement. And to see an example of the format of the problems for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data used for this assignment\n",
    "#   For just this week we're going to write \"in-line\" code - i.e., all the code is in one long list of code. Starting\n",
    "#   next week we'll break code up into functions so we can re-use it/change the data. For this assignment, I'm \"hard coding\"\n",
    "#   the \"data\" in this variable\n",
    "\n",
    "test_list_one = [-0.75, -0.25, 1.0 / 3.0, 2.0 / 3.0, 3.0 / 3.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item -0.75 is negative\n",
      "Item -0.25 is negative\n",
      "Item 0.3333333333333333 is positive\n",
      "Item 0.6666666666666666 is positive\n",
      "Item 1.0 is positive\n"
     ]
    }
   ],
   "source": [
    "## EXAMPLE CODE\n",
    "# Cells labeled EXAMPLE CODE have code in them that you should understand before you start the problem. Usually, they'll be\n",
    "#  code that you'll want to copy and edit for the TODO in the main problem, along with some explanations of what the code\n",
    "#  is and how it works.\n",
    "\n",
    "# Loop over a list and print out whether the element is positive or negative\n",
    "for item in test_list_one:\n",
    "    if item < 0:\n",
    "        # see tutorial on strings for the syntax of f\"\"\n",
    "        print(f\"Item {item} is negative\")\n",
    "    elif item > 0:\n",
    "        print(f\"Item {item} is positive\")\n",
    "    else:\n",
    "        print(f\"Item {item} is zero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# Scratch cells are for you to use to try something out - usually a simpler version of the problem. These are not\n",
    "#  graded, although make sure they execute properly \n",
    "\n",
    "# Suggestion: If doing the full positive-negative split is too complicated, try writing a for loop that just\n",
    "#  loops over all of the items in test_list_one and adds them up and counts how many there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the stats you will be calculating. This is more elegant/useful than creating four variables - it keeps all\n",
    "#  of the values in the same place and assigns a meaningful label (key) to them\n",
    "# See the tutorial on dictionaries on how to set/get key-value pairs in a dictionary\n",
    "dict_save_stats = {\"Mean positive\": 0.0, \"Mean negative\": -0.0, \"Count positive\": 0, \"Count negative\": 0}\n",
    "\n",
    "# TODO: \n",
    "#   Calculate the means and the counts of test_list_one and store them in the dictionary with the keys given above in dict_save_stats\n",
    "#   You'll need a for loop to go over the list and an if statement to separate into positive and negative\n",
    "# Step 1: Copy the for loop from the example code above (try writing it without looking at it first)\n",
    "#  This has the code structure you'll need, but doesn't calculate any stats.\n",
    "# Step 2: Use the dictionary dict_save_stats with the appropriate key to count the number of positives/negatives\n",
    "#    Two options: Create a count variable and set the dictionary entry to the count variable after the for loop\n",
    "#    Use the dictionary entry as the count variable (foo[\"\"] = foo[\"\"] + 1)\n",
    "# Step 3: In the loop add the positive/negative values to the appropriate dictionary entry\n",
    "# Step 4: Don't forget to divide by the count to create the mean\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Test code for list\n",
    "\n",
    "TODO: \n",
    "- Fill in the for loop above\n",
    "- Run the cell below - it will print out if your values are incorrect\n",
    "\n",
    "Next week we'll put the for loop code in a function so that we run it with other data than test_list_data. In the meantime, this is an example of writing test code to check that your code is correct. In this case, you can just look at test_list_data and see what the right answer should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean positive is not correct, should be 0.6666666666666666, got 0.0\n",
      "Mean negative is not correct, should be -0.5, got -0.0\n",
      "Count positive numbers, should be 3, got 0\n",
      "Count positive numbers, should be 2, got 0\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "b_tests_passed = True\n",
    "if not np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0):\n",
    "    b_tests_passed = False\n",
    "    print(f\"Mean positive is not correct, should be {2.0/3.0}, got {dict_save_stats['Mean positive']}\")\n",
    "\n",
    "if not np.isclose(dict_save_stats[\"Mean negative\"], -0.5):\n",
    "    b_tests_passed = False\n",
    "    print(f\"Mean negative is not correct, should be -0.5, got {dict_save_stats['Mean negative']}\")\n",
    "\n",
    "# != is not equals\n",
    "if dict_save_stats[\"Count positive\"] != 3:\n",
    "    b_tests_passed = False\n",
    "    print(f\"Count positive numbers, should be 3, got {dict_save_stats['Count positive']}\")\n",
    "\n",
    "if dict_save_stats[\"Count negative\"] != 2:\n",
    "    b_tests_passed = False\n",
    "    print(f\"Count positive numbers, should be 2, got {dict_save_stats['Count negative']}\")\n",
    "\n",
    "if b_tests_passed:\n",
    "    print(\"All array tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## A note on the autograder. \n",
    "\n",
    "As tempting as it might be to just write the number in to make the test work (instead of calculating it) you will get a zero for doing so. I.e., do not just put 2/3 into the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>list</pre> results:</strong></p><p><strong><pre style='display: inline;'>list - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in list 0\n",
       "    Failed example:\n",
       "        assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest list 0[0]>\", line 1, in <module>\n",
       "            assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>list - 2</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in list 1\n",
       "    Failed example:\n",
       "        assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest list 1[0]>\", line 1, in <module>\n",
       "            assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>list - 3</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in list 2\n",
       "    Failed example:\n",
       "        assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest list 2[0]>\", line 1, in <module>\n",
       "            assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>list - 4</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in list 3\n",
       "    Failed example:\n",
       "        assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest list 3[0]>\", line 1, in <module>\n",
       "            assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
       "        AssertionError\n",
       "</pre>"
      ],
      "text/plain": [
       "list results:\n",
       "    list - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in list 0\n",
       "        Failed example:\n",
       "            assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest list 0[0]>\", line 1, in <module>\n",
       "                assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
       "            AssertionError\n",
       "\n",
       "    list - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in list 1\n",
       "        Failed example:\n",
       "            assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest list 1[0]>\", line 1, in <module>\n",
       "                assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
       "            AssertionError\n",
       "\n",
       "    list - 3 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in list 2\n",
       "        Failed example:\n",
       "            assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest list 2[0]>\", line 1, in <module>\n",
       "                assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
       "            AssertionError\n",
       "\n",
       "    list - 4 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in list 3\n",
       "        Failed example:\n",
       "            assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest list 3[0]>\", line 1, in <module>\n",
       "                assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
       "            AssertionError"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Question 2: Doing it again with a numpy array\n",
    "\n",
    "TODO: Same as the previous question, but this time do it for a numpy array\n",
    "- NO **if** statements or **for** loops - do this all with numpy operations\n",
    "\n",
    "You might find \"count_nonzero\" useful.\n",
    "\n",
    "As before, test code is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data for this problem - this takes the list and converts it to a numpy array\n",
    "# Use the variable window (click on variables above) to see the difference between test_list_one and\n",
    "#  test_nparra - they should have the same values, they're just stored differently\n",
    "test_nparray = np.array(test_list_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min is -0.75\n",
      "Negative elements [-0.75 -0.25]\n",
      "Count negative 2\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE CODE\n",
    "# Numpy has built-in functions to do most of what you want to do\n",
    "#   this essentially does a for loop over the array and looks for the min\n",
    "example_min = np.min(test_nparray)\n",
    "print(f\"Min is {example_min}\")\n",
    "\n",
    "# But what if you want to do the if < 0 part? This is where boolean indexing comes in.\n",
    "#   Look at this variable in the variable window - this is another numpy array, but this time the array is full of \n",
    "#   False and True - it is True where the corresponding element in test_nparray is negative\n",
    "b_is_negative = test_nparray < 0\n",
    "\n",
    "# You can use this boolean array to get just the elements in the original list that were negative\n",
    "all_negative = test_nparray[b_is_negative]\n",
    "print(f\"Negative elements {all_negative}\")\n",
    "\n",
    "# or use another numpy method to count the number of non-zero - note, False is zero and True is non-zero\n",
    "#  Notice that this time the call to np is inside of the print statement - you can always take a piece\n",
    "#  of code and assign it to a variable.\n",
    "#     Try doing my_count = np.count_nonzero(b_is_negative)\n",
    "# If you get syntax errors, break the code up this way to find what part of the code is \"broken\"\n",
    "print(f\"Count negative {np.count_nonzero(b_is_negative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate these stats for test_nparray. The answers should be the same as the ones above.\n",
    "#   Do NOT just set the values - you must calculate them\n",
    "dict_save_stats_np = {\"Mean positive\": 0, \"Mean negative\": 0, \"Count positive\": 0, \"Count negative\": 0}\n",
    "\n",
    "# TODO: Calculate the mean for the positive and the negative values\n",
    "#.  Also count the number of each\n",
    "#   Do NOT use a for loop - use boolean indexing (see example above)\n",
    "\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SELF TESTS\n",
    "#  Use this cell to write any additional test code for yourself. For example, you could copy the tests from the list version\n",
    "#  and use them here, just check the values in dict_save_stats_np instead of dict_save_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>nparray</pre> results:</strong></p><p><strong><pre style='display: inline;'>nparray - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in nparray 0\n",
       "    Failed example:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest nparray 0[0]>\", line 1, in <module>\n",
       "            assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>nparray - 2</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in nparray 1\n",
       "    Failed example:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest nparray 1[0]>\", line 1, in <module>\n",
       "            assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>nparray - 3</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in nparray 2\n",
       "    Failed example:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest nparray 2[0]>\", line 1, in <module>\n",
       "            assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>nparray - 4</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in nparray 3\n",
       "    Failed example:\n",
       "        assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest nparray 3[0]>\", line 1, in <module>\n",
       "            assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
       "        AssertionError\n",
       "</pre>"
      ],
      "text/plain": [
       "nparray results:\n",
       "    nparray - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in nparray 0\n",
       "        Failed example:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest nparray 0[0]>\", line 1, in <module>\n",
       "                assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
       "            AssertionError\n",
       "\n",
       "    nparray - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in nparray 1\n",
       "        Failed example:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest nparray 1[0]>\", line 1, in <module>\n",
       "                assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
       "            AssertionError\n",
       "\n",
       "    nparray - 3 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in nparray 2\n",
       "        Failed example:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest nparray 2[0]>\", line 1, in <module>\n",
       "                assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
       "            AssertionError\n",
       "\n",
       "    nparray - 4 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in nparray 3\n",
       "        Failed example:\n",
       "            assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest nparray 3[0]>\", line 1, in <module>\n",
       "                assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
       "            AssertionError"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"nparray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Queston 3: Fix, please -  Uh oh, it doesn't work\n",
    "\n",
    "There is additional information on this problem in the Lab slides:  https://docs.google.com/presentation/d/1lVYGqoStt0ZdnRAYMfF9Km6f0NgMNkuYgINsRhXASwI/edit?usp=sharing; read those slides first\n",
    "\n",
    "TODO: Each of the following cells had code that is \"broken\" - either it generates a syntax error OR it doesn't do what the comment says it does. TODO Fix what's broken so the grader tests pass.\n",
    "\n",
    "TODO: Read carefully through the next cell. It sets up the data you'll be using for these problems, and also has example array slicing you'll need to fix the broken bits\n",
    "\n",
    "Reminder: If you don't understand a complex piece of code, you can always break it apart. For example:\n",
    "\n",
    "**min_xy = np.min(test_data[0,1:3])**\n",
    "\n",
    "Can be broken up into two lines by creating another variable to hold the slice result\n",
    "\n",
    "**sliced_data = test_data[0,1:3]**\n",
    "\n",
    "**min_xy = np.min(sliced_data)**\n",
    "\n",
    "This makes it a lot easier to see if, for example, sliced_data is actually the slice you want (by printing it out or looking at it in the variable window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Making a data set to practice with before lab/homework\n",
    "#  This is a simplified version of the data set we'll work with\n",
    "#  It consists of x, y, z data for 10 time steps for 5 samples\n",
    "#  The x data is all between 0 and 1, the y data 0 and -1, z data 10-20\n",
    "#  The last column is 1 if the sample is good, 0 if it is bad\n",
    "#  The data is stored in a 5 x [3 * 10 + 1] array\n",
    "#  Each row (one row for each sample) looks like this\n",
    "#    x0 y0 z0 x1 y1 z1 .... x9 y9 z9 1 or 0\n",
    "\n",
    "# Make space for all of the data and fill it with zeros\n",
    "#   zeros takes a tuple with the data sizes - in this case we are making a 2 dimensional array\n",
    "#   with 5 columns (one for each sample) and 10 x,y,z value (30 total) and one extra column for the good/bad\n",
    "my_test_data = np.zeros((5, 3 * 10 + 1))\n",
    "\n",
    "# Fill in whether or not the sample is good. Every other one is good, the others are bad\n",
    "# Since zero is bad - and the array is all zeros - just set every other row, last column\n",
    "#   The -1 picks the last column, the 0::2 picks every other row\n",
    "#   Note: The left hand side has 3 elements, the right a single number - numpy interprets this to mean\n",
    "#     set all of those values to the single number\n",
    "my_test_data[0::2, -1] = 1\n",
    "\n",
    "# Fill in the x values for each sample with 0, 0.1... 1.0\n",
    "#  np.linspace() generates uniformly-spaced samples from start to stop\n",
    "#    You can assign values to specific parameters by name if you want\n",
    "#    This would be the same as np.linspace(0, 1.0, 10)\n",
    "# In this case, the array on the left hand side is 5 x 10, so we're going to use a loop to set each row\n",
    "#  to 0, 0.1 etc. one row at a time\n",
    "# shape is the size of the array; we want the number of rows so use .shape[0]\n",
    "x_data_for_one_row = np.linspace(start=0, stop=1.0, num=10)\n",
    "for r in range(0, my_test_data.shape[0]):\n",
    "    # loop through each row r\n",
    "    # Fill in column 0 to one before the end (don't overwrite the good/bad), skipping every 3\n",
    "    my_test_data[r, 0:-2:3] = x_data_for_one_row\n",
    "\n",
    "# Fill in the y values for each sample with random values\n",
    "#  np.random.uniform() generates random samples between the two values; unlike linsapce, you can set the size\n",
    "#   of the numpy array it returns. \n",
    "# The left side is all rows (5 - :) and every 3rd column starting at 1\n",
    "y_data_for_all_rows = np.random.uniform(-1.0, 0.0, size=(5, 10))\n",
    "my_test_data[:, 1::3] = y_data_for_all_rows\n",
    "\n",
    "# Now the z values - notice that we start at column 2 instead of 1\n",
    "my_test_data[:, 2::3] = np.random.uniform(10.0, 20.0, size=(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## What are the dimensions of the data?\n",
    "\n",
    "We know what the dimensions of the data are - we just made it in the cell above. Pretend for a moment that you just read **my_test_data** in from a file and you don't know how many samples there are or how many time steps. You **do** know that each sample has an x,y, and z value for each time step, and that the last column is the success/fail column\n",
    "\n",
    "Again, for these quesitons you need to calculate the value from the data, not just put the number in, except where noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Number of samples - this is correct\n",
    "n_samples = my_test_data.shape[0]\n",
    "\n",
    "# Number of dimensions for each time step - we know this is 3, so set it to 3 - this is correct\n",
    "n_xyz = 3\n",
    "\n",
    "# FIX ME: Number of time steps\n",
    "n_time_steps = my_test_data.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get out just the x values for sample 2\n",
    "#   Note, this is a somewhat subtle error - look at the size of the x values - it should be n_time_steps (10). WHy\n",
    "#  is it not? How many columns does my_test_data actually have? What happens if you take every 3rd, starting at 0?\n",
    "# FIX ME\n",
    "x_values_sample_2 = my_test_data[1, 0::3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>fix_broken</pre> results:</strong></p><p><strong><pre style='display: inline;'>fix_broken - 1</pre> result:</strong></p><pre>    ✅ Test case passed</pre><p><strong><pre style='display: inline;'>fix_broken - 2</pre> result:</strong></p><pre>    ✅ Test case passed</pre><p><strong><pre style='display: inline;'>fix_broken - 3</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(n_time_steps == 10)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in fix_broken 2\n",
       "    Failed example:\n",
       "        assert(n_time_steps == 10)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest fix_broken 2[0]>\", line 1, in <module>\n",
       "            assert(n_time_steps == 10)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>fix_broken - 4</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(x_values_sample_2.size == 10)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in fix_broken 3\n",
       "    Failed example:\n",
       "        assert(x_values_sample_2.size == 10)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest fix_broken 3[0]>\", line 1, in <module>\n",
       "            assert(x_values_sample_2.size == 10)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>fix_broken - 5</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in fix_broken 4\n",
       "    Failed example:\n",
       "        assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest fix_broken 4[0]>\", line 1, in <module>\n",
       "            assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
       "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages/numpy/core/numeric.py\", line 2351, in isclose\n",
       "            return within_tol(x, y, atol, rtol)\n",
       "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages/numpy/core/numeric.py\", line 2332, in within_tol\n",
       "            return less_equal(abs(x-y), atol + rtol * abs(y))\n",
       "                                  ~^~\n",
       "        ValueError: operands could not be broadcast together with shapes (11,) (10,) \n",
       "</pre>"
      ],
      "text/plain": [
       "fix_broken results:\n",
       "    fix_broken - 1 result:\n",
       "        ✅ Test case passed\n",
       "\n",
       "    fix_broken - 2 result:\n",
       "        ✅ Test case passed\n",
       "\n",
       "    fix_broken - 3 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(n_time_steps == 10)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in fix_broken 2\n",
       "        Failed example:\n",
       "            assert(n_time_steps == 10)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest fix_broken 2[0]>\", line 1, in <module>\n",
       "                assert(n_time_steps == 10)\n",
       "            AssertionError\n",
       "\n",
       "    fix_broken - 4 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(x_values_sample_2.size == 10)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in fix_broken 3\n",
       "        Failed example:\n",
       "            assert(x_values_sample_2.size == 10)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest fix_broken 3[0]>\", line 1, in <module>\n",
       "                assert(x_values_sample_2.size == 10)\n",
       "            AssertionError\n",
       "\n",
       "    fix_broken - 5 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in fix_broken 4\n",
       "        Failed example:\n",
       "            assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest fix_broken 4[0]>\", line 1, in <module>\n",
       "                assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
       "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages/numpy/core/numeric.py\", line 2351, in isclose\n",
       "                return within_tol(x, y, atol, rtol)\n",
       "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/site-packages/numpy/core/numeric.py\", line 2332, in within_tol\n",
       "                return less_equal(abs(x-y), atol + rtol * abs(y))\n",
       "                                      ~^~\n",
       "            ValueError: operands could not be broadcast together with shapes (11,) (10,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"fix_broken\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"not filled out\"}\n",
    "# List of URLS TCS3 (creates a set)\n",
    "websites = {\"not filled out\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>hours_collaborators</pre> results:</strong></p><p><strong><pre style='display: inline;'>hours_collaborators - 1</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(not \"not filled out\" in worked_with_names)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in hours_collaborators 0\n",
       "    Failed example:\n",
       "        assert(not \"not filled out\" in worked_with_names)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest hours_collaborators 0[0]>\", line 1, in <module>\n",
       "            assert(not \"not filled out\" in worked_with_names)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>hours_collaborators - 2</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(not \"not filled out\" in websites)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in hours_collaborators 1\n",
       "    Failed example:\n",
       "        assert(not \"not filled out\" in websites)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest hours_collaborators 1[0]>\", line 1, in <module>\n",
       "            assert(not \"not filled out\" in websites)\n",
       "        AssertionError\n",
       "</pre><p><strong><pre style='display: inline;'>hours_collaborators - 3</pre> result:</strong></p><pre>    ❌ Test case failed\n",
       "    Trying:\n",
       "        assert(hours > 0)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in hours_collaborators 2\n",
       "    Failed example:\n",
       "        assert(hours > 0)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest hours_collaborators 2[0]>\", line 1, in <module>\n",
       "            assert(hours > 0)\n",
       "        AssertionError\n",
       "</pre>"
      ],
      "text/plain": [
       "hours_collaborators results:\n",
       "    hours_collaborators - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(not \"not filled out\" in worked_with_names)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in hours_collaborators 0\n",
       "        Failed example:\n",
       "            assert(not \"not filled out\" in worked_with_names)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest hours_collaborators 0[0]>\", line 1, in <module>\n",
       "                assert(not \"not filled out\" in worked_with_names)\n",
       "            AssertionError\n",
       "\n",
       "    hours_collaborators - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(not \"not filled out\" in websites)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in hours_collaborators 1\n",
       "        Failed example:\n",
       "            assert(not \"not filled out\" in websites)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest hours_collaborators 1[0]>\", line 1, in <module>\n",
       "                assert(not \"not filled out\" in websites)\n",
       "            AssertionError\n",
       "\n",
       "    hours_collaborators - 3 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert(hours > 0)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in hours_collaborators 2\n",
       "        Failed example:\n",
       "            assert(hours > 0)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/workspaces/IntroPythonProgramming/.conda/lib/python3.12/doctest.py\", line 1361, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest hours_collaborators 2[0]>\", line 1, in <module>\n",
       "                assert(hours > 0)\n",
       "            AssertionError"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To submit\n",
    "\n",
    "- Remove any print statements that print out a lot of stuff\n",
    "- Do a restart then run all to make sure everything runs ok\n",
    "- Save the file\n",
    "- Submit this .ipynb file through gradescope, lecture activity 1 data structures. \n",
    "\n",
    "See detailed instructions here\n",
    "    https://docs.google.com/presentation/d/1tYa5oycUiG4YhXUq5vHvPOpWJ4k_xUPp2rUNIL7Q9RI/edit?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "fix_broken": {
     "name": "fix_broken",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(n_samples == 5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(n_xyz == 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(n_time_steps == 10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(x_values_sample_2.size == 10)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.any(np.isclose(x_values_sample_2, np.linspace(0, 1, 10))))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(not \"not filled out\" in worked_with_names)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(not \"not filled out\" in websites)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(hours > 0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "list": {
     "name": "list",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert np.isclose(dict_save_stats[\"Mean positive\"], 2.0 / 3.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_save_stats[\"Mean negative\"], -0.5)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_save_stats[\"Count positive\"], 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert np.isclose(dict_save_stats[\"Count negative\"], 2)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "nparray": {
     "name": "nparray",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(np.isclose(dict_save_stats_np[\"Mean positive\"], 2.0 / 3.0))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(dict_save_stats_np[\"Mean negative\"], -0.5))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(dict_save_stats_np[\"Count positive\"], 3))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(dict_save_stats_np[\"Count negative\"], 2))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
